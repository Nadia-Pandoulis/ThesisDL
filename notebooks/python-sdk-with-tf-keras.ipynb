{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7583a486-afd6-42d8-934b-fdb33a6f3362",
      "metadata": {
        "tags": [],
        "id": "7583a486-afd6-42d8-934b-fdb33a6f3362"
      },
      "source": [
        "# Bushfire Detection Model Development\n",
        "Using the Edge Impulse Python SDK with TensorFlow and Keras to train model to detect bushfires vs. no bushfire within a given image."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Dependencies"
      ],
      "metadata": {
        "id": "V0C6D6JxLU_7"
      },
      "id": "V0C6D6JxLU_7"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0de311a-de4c-4fe1-8dd9-e7b2206217d0",
      "metadata": {
        "id": "e0de311a-de4c-4fe1-8dd9-e7b2206217d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e179a176-a603-402a-d7c8-3b9d319a8d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: edgeimpulse in /usr/local/lib/python3.11/dist-packages (1.0.18)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.2.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.71.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (78.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.13.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: edgeimpulse-api<2.0.0,>=1.61.23 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse) (1.71.13)\n",
            "Requirement already satisfied: python-socketio<6.0.0,>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (5.12.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse) (2.32.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: aenum<4.0.0,>=3.1.11 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (3.1.15)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.2 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (1.10.21)\n",
            "Requirement already satisfied: python_dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from edgeimpulse-api<2.0.0,>=1.61.23->edgeimpulse) (1.26.20)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.2)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (0.23.1)\n",
            "Requirement already satisfied: python-engineio>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (4.11.2)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (2025.1.31)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.2.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio<6.0.0,>=5.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install tensorflow==2.12.0 edgeimpulse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "sWxSB0pKLdM-"
      },
      "id": "sWxSB0pKLdM-"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2f85b7c9-e76b-459e-ac37-4b348cbb5906",
      "metadata": {
        "tags": [],
        "id": "2f85b7c9-e76b-459e-ac37-4b348cbb5906"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import edgeimpulse as ei\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "QWcJurluLmqj"
      },
      "id": "QWcJurluLmqj"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "3429e02d-5188-4215-97c7-5a50b854b06b",
      "metadata": {
        "tags": [],
        "id": "3429e02d-5188-4215-97c7-5a50b854b06b"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "ei.API_KEY = \"ei_c90f6349e4f2624274eff30ee840a3e6412c3135d1651ee15515404d290ce842\"\n",
        "labels = [\"fire\", \"nofire\"]\n",
        "num_classes = len(labels)\n",
        "deploy_filename = \"bushfire_detection_model_cpp.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mMjwVcog-IpL",
        "outputId": "78eb656e-182a-45b2-b205-4b18066a10aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mMjwVcog-IpL",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset\n",
        "Organise files between 'Training and Validation' and 'Testing' folders containing 'fire' and 'nofire' images.\n"
      ],
      "metadata": {
        "id": "3GDZhXZTLtAe"
      },
      "id": "3GDZhXZTLtAe"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0a0abd03-9473-4272-b97d-f59cefa44995",
      "metadata": {
        "tags": [],
        "id": "0a0abd03-9473-4272-b97d-f59cefa44995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65d3063-dfe3-4e87-e893-f0d5e8f65b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1467 images belonging to 2 classes.\n",
            "Found 365 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define paths for your dataset\n",
        "train_val_directory = 'drive/MyDrive/forest_fire/Training and Validation'\n",
        "test_directory = 'drive/MyDrive/forest_fire/Testing'\n",
        "\n",
        "# Create an ImageDataGenerator for training and validation\n",
        "train_val_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,        # Normalize pixel values\n",
        "    validation_split=0.2      # Use 20% of the training data for validation\n",
        ")\n",
        "\n",
        "# Create generators for training and validation data\n",
        "train_generator = train_val_datagen.flow_from_directory(\n",
        "    train_val_directory,\n",
        "    target_size=(128, 128),   # Resize images to 128x128\n",
        "    batch_size=32,             # Number of images to return in each batch\n",
        "    class_mode='binary',       # Binary classification (fire or no fire)\n",
        "    subset='training',          # Set as training data\n",
        "    classes=['fire', 'nofire'] # Explicitly specify the class names\n",
        ")\n",
        "\n",
        "validation_generator = train_val_datagen.flow_from_directory(\n",
        "    train_val_directory,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',       # Binary classification\n",
        "    subset='validation',        # Set as validation data\n",
        "    classes=['fire', 'nofire'] # Explicitly specify the class names\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup of 'Testing' directory"
      ],
      "metadata": {
        "id": "dnolBQY6MrJt"
      },
      "id": "dnolBQY6MrJt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ImageDataGenerator for testing (no split needed)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Create a generator for the test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',       # Binary classification\n",
        "    shuffle=False,             # Don't shuffle test data\n",
        "    classes=['fire', 'nofire'] # Explicitly specify the class names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j-5sWKABMEp",
        "outputId": "dbec60ff-b5f2-4fbd-afe7-272153191887"
      },
      "id": "1j-5sWKABMEp",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 68 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building and compiling model"
      ],
      "metadata": {
        "id": "w2UTngUXMxF0"
      },
      "id": "w2UTngUXMxF0"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ba42755e-b13c-4e84-a016-4e4fcf4be9f6",
      "metadata": {
        "tags": [],
        "id": "ba42755e-b13c-4e84-a016-4e4fcf4be9f6"
      },
      "outputs": [],
      "source": [
        "# Build your model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing model setup"
      ],
      "metadata": {
        "id": "7tg701dmOdIb"
      },
      "id": "7tg701dmOdIb"
    },
    {
      "source": [
        "print(train_generator.class_indices)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teYM2iWqOegp",
        "outputId": "1b7d816b-cf5a-4e5d-f98e-49850825bc0e"
      },
      "id": "teYM2iWqOegp",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fire': 0, 'nofire': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "bx2t60lWM7r3"
      },
      "id": "bx2t60lWM7r3"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d6ddf625-43c9-40da-9c44-7fbbbea8b572",
      "metadata": {
        "tags": [],
        "id": "d6ddf625-43c9-40da-9c44-7fbbbea8b572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "b5bd790a-8c21-4011-ab27-0497974d7e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.11/dist-packages/keras/backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ab08aaafffe8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf__train_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.11/dist-packages/keras/backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Accuracy and Evaluation"
      ],
      "metadata": {
        "id": "mKh_ylDfM_ij"
      },
      "id": "mKh_ylDfM_ij"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "dc2b0ab6-e2d0-4448-9545-4870e5b2d101",
      "metadata": {
        "tags": [],
        "id": "dc2b0ab6-e2d0-4448-9545-4870e5b2d101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e552599-5429-4345-f724-f412dee5f550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 193ms/step - loss: 0.3167 - accuracy: 0.8750\n",
            "Test Accuracy: 0.88\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model to System Compatibility"
      ],
      "metadata": {
        "id": "wF2C2-b_NG-w"
      },
      "id": "wF2C2-b_NG-w"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1b622df2-9745-4c93-969f-35de2ff10df6",
      "metadata": {
        "tags": [],
        "id": "1b622df2-9745-4c93-969f-35de2ff10df6"
      },
      "outputs": [],
      "source": [
        "# List the available profile target devices\n",
        "# ei.model.list_profile_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3c16e2ab-0c50-483e-8d2e-01c2dd48be23",
      "metadata": {
        "tags": [],
        "id": "3c16e2ab-0c50-483e-8d2e-01c2dd48be23"
      },
      "outputs": [],
      "source": [
        "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "# try:\n",
        "#     profile = ei.model.profile(model=model,\n",
        "#                                device='openmv-h7p')\n",
        "#     print(profile.summary())\n",
        "# except Exception as e:\n",
        "#     print(f\"Could not profile: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploying and Downloading Model"
      ],
      "metadata": {
        "id": "Ibc348I9NnRz"
      },
      "id": "Ibc348I9NnRz"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f45a3c73-fbc2-477a-9f8d-04c3e10b1863",
      "metadata": {
        "tags": [],
        "id": "f45a3c73-fbc2-477a-9f8d-04c3e10b1863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61b8b5c-9c18-4344-8920-fdabf3998021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model deployment successful.\n",
            "Model exported as saved_model_zip.zip\n"
          ]
        }
      ],
      "source": [
        "# Define the output and input types for your model\n",
        "model_output_type = ei.model.output_type.Classification(labels=labels)\n",
        "\n",
        "# Define the model input type for images\n",
        "model_input_type = ei.model.input_type.ImageInput()\n",
        "\n",
        "# Define the filename for the deployment package\n",
        "deploy_filename = \"saved_model_zip.zip\"\n",
        "\n",
        "# Save your model as a TensorFlow SavedModel first\n",
        "model.save(\"saved_model\")  # Save model in the correct format\n",
        "\n",
        "# Try to deploy the model directly as a C++ library in a .zip file\n",
        "deploy_bytes = None\n",
        "try:\n",
        "    # Specify the path to the saved model\n",
        "    deploy_bytes = ei.model.deploy(\n",
        "        model=\"saved_model\",  # Path to the saved model\n",
        "        model_output_type=model_output_type,\n",
        "        model_input_type=model_input_type,\n",
        "        deploy_target='zip'  # Export as a .zip file with C++ library\n",
        "    )\n",
        "    print(\"Model deployment successful.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not deploy: {e}\")\n",
        "\n",
        "# Write the deployed model bytes to a file\n",
        "if deploy_bytes:\n",
        "    with open(deploy_filename, 'wb') as f:\n",
        "        f.write(deploy_bytes.getvalue())\n",
        "    print(f\"Model exported as {deploy_filename}\")\n",
        "else:\n",
        "    print(\"Deployment failed; no deployable bytes were generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"saved_model\", 'zip', \"saved_model\")\n",
        "files.download(\"saved_model.zip\")"
      ],
      "metadata": {
        "id": "SrWWW-ZKzG9h",
        "outputId": "54b76c23-d63b-42c4-f14d-6c4dc17ff4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "SrWWW-ZKzG9h",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fb36f413-70ca-41d3-8f89-89a2618ffa19\", \"saved_model.zip\", 52497)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Specifications\n",
        "Code to check if model has been trained correctly"
      ],
      "metadata": {
        "id": "A4pSOhuNKyXL"
      },
      "id": "A4pSOhuNKyXL"
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrbKsNsQKU3e",
        "outputId": "5fccbf50-7096-4d89-f759-964baed0f892"
      },
      "id": "SrbKsNsQKU3e",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 32)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}